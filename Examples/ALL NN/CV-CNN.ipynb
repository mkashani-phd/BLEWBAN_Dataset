{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can run pip3 install -r requirements.txt to install all the packages\n",
    "## but you need to install tensorflow or pytorch or keras manually\n",
    "import pickle\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import threading, os, sys\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # try to use CPU only\n",
    "\n",
    "# addin path to import IQ module\n",
    "sys.path.append('../../')\n",
    "import src.IQ as IQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "myclient = pymongo.MongoClient(\"mongodb://test:12345678910111213@SG-pine-beat-9444-57323.servers.mongodirector.com:27017/BLE\")\n",
    "BLE = myclient[\"BLE\"]\n",
    "\n",
    "def query(collection, filter:dict, addFrameColumn=True):\n",
    "    df =  pd.DataFrame(list(collection.find(filter)))\n",
    "    if addFrameColumn:\n",
    "        df['frame'] = df.apply(lambda x: x['I'] + np.dot(x['Q'],1j), axis=1)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq = IQ.IQ(Fc=2439810000+.1e4)\n",
    "\n",
    "def configCreator(downSampleRate = 10, cutoff = 1e6):\n",
    "    downSampleRate= max(downSampleRate, 1)\n",
    "    return {                                      \n",
    "            iq.butter:{'Fs': iq.Fs/downSampleRate, \"cutoff\": cutoff},\n",
    "            iq.downSample:{'downSampleRate':downSampleRate, \"shift\": 0},\n",
    "            iq.demodulate:{'Fs': iq.Fs},\n",
    "           }\n",
    "\n",
    "downSampleRate = 1\n",
    "methods = configCreator(downSampleRate=  downSampleRate)\n",
    "\n",
    "# with open('data/E1.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "# df = pd.DataFrame(data)\n",
    "# df['frame'] = df.apply(lambda x: x['I'] + np.dot(x['Q'],1j), axis=1)\n",
    "\n",
    "df = query(BLE['onBody'], {})\n",
    "df['data'] = iq.apply(methods = methods, frame = df)\n",
    "\n",
    "############### Defing and normalizing the input #############\n",
    "# df['normalized_input_feature'] = df['data'].apply(lambda x: fft_normalized(x, threshold = 1))\n",
    "df['normalized_input_feature'] = df['data'].apply(lambda x: x[0:2000//downSampleRate])\n",
    "# df['normalized_input_feature_realImage'] = df['normalized_input_feature'].apply(lambda x: np.concatenate([np.real(x[0:2000]), np.imag(x[0:2000])]).reshape(2,-1))\n",
    "##################################################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['normalized_input_feature'], df['dvc'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1158,), (290,), (1158,), (290,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 10:56:18.835769: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 10:56:18.942794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-21 10:56:18.942833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-21 10:56:18.956022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-21 10:56:18.992958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 10:56:19.915554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-21 10:56:20.620209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.692394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.692514: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.693659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.693751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.693827: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.748850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.748972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.749057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-21 10:56:20.749115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20947 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train.tolist())\n",
    "X_test =  tf.convert_to_tensor(X_test.tolist())\n",
    "y_train =  tf.convert_to_tensor(y_train.tolist())\n",
    "y_test = tf.convert_to_tensor(y_test.tolist())\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (ComplexInput)      [(None, 2000, 1)]         0         \n",
      "                                                                 \n",
      " complex_conv1d_12 (Complex  (None, 1873, 2)           516       \n",
      " Conv1D)                                                         \n",
      "                                                                 \n",
      " complex_avg_pooling1d_12 (  (None, 936, 2)            0         \n",
      " ComplexAvgPooling1D)                                            \n",
      "                                                                 \n",
      " complex_conv1d_13 (Complex  (None, 809, 2)            1028      \n",
      " Conv1D)                                                         \n",
      "                                                                 \n",
      " complex_avg_pooling1d_13 (  (None, 404, 2)            0         \n",
      " ComplexAvgPooling1D)                                            \n",
      "                                                                 \n",
      " complex_flatten_6 (Complex  (None, 808)               0         \n",
      " Flatten)                                                        \n",
      "                                                                 \n",
      " complex_dropout_6 (Complex  (None, 808)               0         \n",
      " Dropout)                                                        \n",
      "                                                                 \n",
      " complex_dense_6 (ComplexDe  (None, 100)               161800    \n",
      " nse)                                                            \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 13)                1313      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174757 (682.64 KB)\n",
      "Trainable params: 174757 (682.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model()\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Early stopping\u001b[39;00m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import cvnn.layers as complex_layers\n",
    "import cvnn.losses as complex_losses\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "def get_model(downSampleRate = 1):\n",
    "    inputs = complex_layers.complex_input(shape=(2000//downSampleRate,1,))\n",
    "    c0 = complex_layers.ComplexConv1D(filters= 2, activation='cart_relu', kernel_size=128//downSampleRate)(inputs)\n",
    "    # c0 = complex_layers.ComplexConv1D(filters= 2, activation='cart_relu', kernel_size=128//downSampleRate)(c0)\n",
    "    c0 = complex_layers.ComplexAvgPooling1D(pool_size=2)(c0)\n",
    "    c1 = complex_layers.ComplexConv1D(filters= 2, activation='cart_relu', kernel_size=128//downSampleRate)(c0)\n",
    "    # c1 = complex_layers.ComplexConv1D(filters= 2, activation='cart_relu', kernel_size=128//downSampleRate)(c1)\n",
    "    c1 = complex_layers.ComplexAvgPooling1D(pool_size=2)(c1)\n",
    "    # c1 = complex_layers.ComplexDropout(0.1/downSampleRate)(c1)\n",
    "    c1 = complex_layers.ComplexFlatten()(c1)\n",
    "    # c1 = complex_layers.ComplexDense(64, activation='cart_relu', kernel_regularizer=regularizers.L1(0.001))(c1)\n",
    "    c1 = complex_layers.ComplexDropout(0.1/downSampleRate)(c1)\n",
    "    out = complex_layers.ComplexDense(100, activation='convert_to_real_with_abs', kernel_regularizer=regularizers.L1(0.0001))(c1)\n",
    "\n",
    "    out = Dense(100, activation='relu')(out)\n",
    "    out = Dense(13, activation='softmax')(out)  # 13 classes\n",
    "\n",
    "    return tf.keras.Model(inputs, out)\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "1/0\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=512, batch_size=1000, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping],verbose=1)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_old, X_test_old, y_train_old, y_test_old = train_test_split(df['normalized_input_feature_realImage'], df['dvc'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_old = tf.convert_to_tensor(X_train_old.tolist())\n",
    "X_test_old =  tf.convert_to_tensor(X_test_old.tolist())\n",
    "y_train_old =  tf.convert_to_tensor(y_train_old.tolist())\n",
    "y_test_old = tf.convert_to_tensor(y_test_old.tolist())\n",
    "\n",
    "data_shape = len(df['data'][0])\n",
    "\n",
    "y_train_encoded_old = to_categorical(y_train_old)\n",
    "y_test_encoded_old = to_categorical(y_test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2576, 2, 2000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 10:49:31.867453: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-13 10:49:31.891792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 10:49:31.891819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 10:49:31.892485: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 10:49:31.896600: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 10:49:32.414477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 2, 2000, 1] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Conv2D, Flatten, Dropout, Input\n\u001b[1;32m      5\u001b[0m input_data \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m Conv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,)(x)\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m)(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[1;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[1;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 2, 2000, 1] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import cvnn.layers as complex_layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, Input\n",
    "\n",
    "input_data = Input(shape=(2,2000,1,))\n",
    "x = Conv2D(filters=5, kernel_size=128, activation='relu',)(input_data)\n",
    "x = Conv2D(filters=5, kernel_size=128, activation='relu',)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu',kernel_regularizer=regularizers.L1(0.001))(x)\n",
    "x = Dense(100, activation='relu',kernel_regularizer=regularizers.L1(0.001))(x)\n",
    "output = Dense(y_test_encoded.shape[1], activation='softmax')(x)  # 13 classes\n",
    "\n",
    "\n",
    "model = Model(inputs=input_data, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_old, y_train_encoded_old, epochs=512, batch_size=64, validation_data=(X_test_old, y_test_encoded_old))\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss_old, accuracy_old = model.evaluate(X_test_old, y_test_encoded_old)\n",
    "print(f'Test accuracy: {accuracy_old}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 12839007.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 108447353.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 14338238.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 35876702.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Train Epoch:   0 [     0/ 60000 (  0%)]\tLoss: 2.437958\n",
      "Train Epoch:   0 [  6400/ 60000 ( 11%)]\tLoss: 0.084289\n",
      "Train Epoch:   0 [ 12800/ 60000 ( 21%)]\tLoss: 0.057723\n",
      "Train Epoch:   0 [ 19200/ 60000 ( 32%)]\tLoss: 0.127695\n",
      "Train Epoch:   0 [ 25600/ 60000 ( 43%)]\tLoss: 0.099930\n",
      "Train Epoch:   0 [ 32000/ 60000 ( 53%)]\tLoss: 0.036542\n",
      "Train Epoch:   0 [ 38400/ 60000 ( 64%)]\tLoss: 0.041900\n",
      "Train Epoch:   0 [ 44800/ 60000 ( 75%)]\tLoss: 0.030878\n",
      "Train Epoch:   0 [ 51200/ 60000 ( 85%)]\tLoss: 0.003791\n",
      "Train Epoch:   0 [ 57600/ 60000 ( 96%)]\tLoss: 0.036098\n",
      "Train Epoch:   1 [     0/ 60000 (  0%)]\tLoss: 0.102802\n",
      "Train Epoch:   1 [  6400/ 60000 ( 11%)]\tLoss: 0.013273\n",
      "Train Epoch:   1 [ 12800/ 60000 ( 21%)]\tLoss: 0.004755\n",
      "Train Epoch:   1 [ 19200/ 60000 ( 32%)]\tLoss: 0.068182\n",
      "Train Epoch:   1 [ 25600/ 60000 ( 43%)]\tLoss: 0.052206\n",
      "Train Epoch:   1 [ 32000/ 60000 ( 53%)]\tLoss: 0.081062\n",
      "Train Epoch:   1 [ 38400/ 60000 ( 64%)]\tLoss: 0.014868\n",
      "Train Epoch:   1 [ 44800/ 60000 ( 75%)]\tLoss: 0.049419\n",
      "Train Epoch:   1 [ 51200/ 60000 ( 85%)]\tLoss: 0.002171\n",
      "Train Epoch:   1 [ 57600/ 60000 ( 96%)]\tLoss: 0.015023\n",
      "Train Epoch:   2 [     0/ 60000 (  0%)]\tLoss: 0.001134\n",
      "Train Epoch:   2 [  6400/ 60000 ( 11%)]\tLoss: 0.039608\n",
      "Train Epoch:   2 [ 12800/ 60000 ( 21%)]\tLoss: 0.032125\n",
      "Train Epoch:   2 [ 19200/ 60000 ( 32%)]\tLoss: 0.001233\n",
      "Train Epoch:   2 [ 25600/ 60000 ( 43%)]\tLoss: 0.013566\n",
      "Train Epoch:   2 [ 32000/ 60000 ( 53%)]\tLoss: 0.002213\n",
      "Train Epoch:   2 [ 38400/ 60000 ( 64%)]\tLoss: 0.020720\n",
      "Train Epoch:   2 [ 44800/ 60000 ( 75%)]\tLoss: 0.005425\n",
      "Train Epoch:   2 [ 51200/ 60000 ( 85%)]\tLoss: 0.042364\n",
      "Train Epoch:   2 [ 57600/ 60000 ( 96%)]\tLoss: 0.033868\n",
      "Train Epoch:   3 [     0/ 60000 (  0%)]\tLoss: 0.001591\n",
      "Train Epoch:   3 [  6400/ 60000 ( 11%)]\tLoss: 0.002597\n",
      "Train Epoch:   3 [ 12800/ 60000 ( 21%)]\tLoss: 0.000523\n",
      "Train Epoch:   3 [ 19200/ 60000 ( 32%)]\tLoss: 0.022320\n",
      "Train Epoch:   3 [ 25600/ 60000 ( 43%)]\tLoss: 0.000972\n",
      "Train Epoch:   3 [ 32000/ 60000 ( 53%)]\tLoss: 0.001144\n",
      "Train Epoch:   3 [ 38400/ 60000 ( 64%)]\tLoss: 0.008388\n",
      "Train Epoch:   3 [ 44800/ 60000 ( 75%)]\tLoss: 0.002824\n",
      "Train Epoch:   3 [ 51200/ 60000 ( 85%)]\tLoss: 0.003181\n",
      "Train Epoch:   3 [ 57600/ 60000 ( 96%)]\tLoss: 0.004607\n",
      "Train Epoch:   4 [     0/ 60000 (  0%)]\tLoss: 0.000820\n",
      "Train Epoch:   4 [  6400/ 60000 ( 11%)]\tLoss: 0.002368\n",
      "Train Epoch:   4 [ 12800/ 60000 ( 21%)]\tLoss: 0.001305\n",
      "Train Epoch:   4 [ 19200/ 60000 ( 32%)]\tLoss: 0.000160\n",
      "Train Epoch:   4 [ 25600/ 60000 ( 43%)]\tLoss: 0.000631\n",
      "Train Epoch:   4 [ 32000/ 60000 ( 53%)]\tLoss: 0.005547\n",
      "Train Epoch:   4 [ 38400/ 60000 ( 64%)]\tLoss: 0.000257\n",
      "Train Epoch:   4 [ 44800/ 60000 ( 75%)]\tLoss: 0.000988\n",
      "Train Epoch:   4 [ 51200/ 60000 ( 85%)]\tLoss: 0.000162\n",
      "Train Epoch:   4 [ 57600/ 60000 ( 96%)]\tLoss: 0.037084\n",
      "Train Epoch:   5 [     0/ 60000 (  0%)]\tLoss: 0.002779\n",
      "Train Epoch:   5 [  6400/ 60000 ( 11%)]\tLoss: 0.000395\n",
      "Train Epoch:   5 [ 12800/ 60000 ( 21%)]\tLoss: 0.000784\n",
      "Train Epoch:   5 [ 19200/ 60000 ( 32%)]\tLoss: 0.002023\n",
      "Train Epoch:   5 [ 25600/ 60000 ( 43%)]\tLoss: 0.000427\n",
      "Train Epoch:   5 [ 32000/ 60000 ( 53%)]\tLoss: 0.047056\n",
      "Train Epoch:   5 [ 38400/ 60000 ( 64%)]\tLoss: 0.003164\n",
      "Train Epoch:   5 [ 44800/ 60000 ( 75%)]\tLoss: 0.002819\n",
      "Train Epoch:   5 [ 51200/ 60000 ( 85%)]\tLoss: 0.003611\n",
      "Train Epoch:   5 [ 57600/ 60000 ( 96%)]\tLoss: 0.000118\n",
      "Train Epoch:   6 [     0/ 60000 (  0%)]\tLoss: 0.001733\n",
      "Train Epoch:   6 [  6400/ 60000 ( 11%)]\tLoss: 0.002642\n",
      "Train Epoch:   6 [ 12800/ 60000 ( 21%)]\tLoss: 0.001134\n",
      "Train Epoch:   6 [ 19200/ 60000 ( 32%)]\tLoss: 0.010011\n",
      "Train Epoch:   6 [ 25600/ 60000 ( 43%)]\tLoss: 0.000209\n",
      "Train Epoch:   6 [ 32000/ 60000 ( 53%)]\tLoss: 0.000750\n",
      "Train Epoch:   6 [ 38400/ 60000 ( 64%)]\tLoss: 0.000426\n",
      "Train Epoch:   6 [ 44800/ 60000 ( 75%)]\tLoss: 0.000388\n",
      "Train Epoch:   6 [ 51200/ 60000 ( 85%)]\tLoss: 0.016945\n",
      "Train Epoch:   6 [ 57600/ 60000 ( 96%)]\tLoss: 0.000510\n",
      "Train Epoch:   7 [     0/ 60000 (  0%)]\tLoss: 0.000488\n",
      "Train Epoch:   7 [  6400/ 60000 ( 11%)]\tLoss: 0.001013\n",
      "Train Epoch:   7 [ 12800/ 60000 ( 21%)]\tLoss: 0.000112\n",
      "Train Epoch:   7 [ 19200/ 60000 ( 32%)]\tLoss: 0.000492\n",
      "Train Epoch:   7 [ 25600/ 60000 ( 43%)]\tLoss: 0.000041\n",
      "Train Epoch:   7 [ 32000/ 60000 ( 53%)]\tLoss: 0.000625\n",
      "Train Epoch:   7 [ 38400/ 60000 ( 64%)]\tLoss: 0.000025\n",
      "Train Epoch:   7 [ 44800/ 60000 ( 75%)]\tLoss: 0.000306\n",
      "Train Epoch:   7 [ 51200/ 60000 ( 85%)]\tLoss: 0.000895\n",
      "Train Epoch:   7 [ 57600/ 60000 ( 96%)]\tLoss: 0.000423\n",
      "Train Epoch:   8 [     0/ 60000 (  0%)]\tLoss: 0.000138\n",
      "Train Epoch:   8 [  6400/ 60000 ( 11%)]\tLoss: 0.000202\n",
      "Train Epoch:   8 [ 12800/ 60000 ( 21%)]\tLoss: 0.001193\n",
      "Train Epoch:   8 [ 19200/ 60000 ( 32%)]\tLoss: 0.000439\n",
      "Train Epoch:   8 [ 25600/ 60000 ( 43%)]\tLoss: 0.001685\n",
      "Train Epoch:   8 [ 32000/ 60000 ( 53%)]\tLoss: 0.001813\n",
      "Train Epoch:   8 [ 38400/ 60000 ( 64%)]\tLoss: 0.004245\n",
      "Train Epoch:   8 [ 44800/ 60000 ( 75%)]\tLoss: 0.000474\n",
      "Train Epoch:   8 [ 51200/ 60000 ( 85%)]\tLoss: 0.000050\n",
      "Train Epoch:   8 [ 57600/ 60000 ( 96%)]\tLoss: 0.000929\n",
      "Train Epoch:   9 [     0/ 60000 (  0%)]\tLoss: 0.000183\n",
      "Train Epoch:   9 [  6400/ 60000 ( 11%)]\tLoss: 0.000974\n",
      "Train Epoch:   9 [ 12800/ 60000 ( 21%)]\tLoss: 0.000143\n",
      "Train Epoch:   9 [ 19200/ 60000 ( 32%)]\tLoss: 0.000525\n",
      "Train Epoch:   9 [ 25600/ 60000 ( 43%)]\tLoss: 0.003575\n",
      "Train Epoch:   9 [ 32000/ 60000 ( 53%)]\tLoss: 0.001121\n",
      "Train Epoch:   9 [ 38400/ 60000 ( 64%)]\tLoss: 0.000051\n",
      "Train Epoch:   9 [ 44800/ 60000 ( 75%)]\tLoss: 0.000197\n",
      "Train Epoch:   9 [ 51200/ 60000 ( 85%)]\tLoss: 0.000006\n",
      "Train Epoch:   9 [ 57600/ 60000 ( 96%)]\tLoss: 0.000019\n",
      "Train Epoch:  10 [     0/ 60000 (  0%)]\tLoss: 0.000083\n",
      "Train Epoch:  10 [  6400/ 60000 ( 11%)]\tLoss: 0.000229\n",
      "Train Epoch:  10 [ 12800/ 60000 ( 21%)]\tLoss: 0.000011\n",
      "Train Epoch:  10 [ 19200/ 60000 ( 32%)]\tLoss: 0.000014\n",
      "Train Epoch:  10 [ 25600/ 60000 ( 43%)]\tLoss: 0.000024\n",
      "Train Epoch:  10 [ 32000/ 60000 ( 53%)]\tLoss: 0.000203\n",
      "Train Epoch:  10 [ 38400/ 60000 ( 64%)]\tLoss: 0.000231\n",
      "Train Epoch:  10 [ 44800/ 60000 ( 75%)]\tLoss: 0.000015\n",
      "Train Epoch:  10 [ 51200/ 60000 ( 85%)]\tLoss: 0.000008\n",
      "Train Epoch:  10 [ 57600/ 60000 ( 96%)]\tLoss: 0.000188\n",
      "Train Epoch:  11 [     0/ 60000 (  0%)]\tLoss: 0.000023\n",
      "Train Epoch:  11 [  6400/ 60000 ( 11%)]\tLoss: 0.000253\n",
      "Train Epoch:  11 [ 12800/ 60000 ( 21%)]\tLoss: 0.000183\n",
      "Train Epoch:  11 [ 19200/ 60000 ( 32%)]\tLoss: 0.000385\n",
      "Train Epoch:  11 [ 25600/ 60000 ( 43%)]\tLoss: 0.000007\n",
      "Train Epoch:  11 [ 32000/ 60000 ( 53%)]\tLoss: 0.000056\n",
      "Train Epoch:  11 [ 38400/ 60000 ( 64%)]\tLoss: 0.000009\n",
      "Train Epoch:  11 [ 44800/ 60000 ( 75%)]\tLoss: 0.000008\n",
      "Train Epoch:  11 [ 51200/ 60000 ( 85%)]\tLoss: 0.000727\n",
      "Train Epoch:  11 [ 57600/ 60000 ( 96%)]\tLoss: 0.000028\n",
      "Train Epoch:  12 [     0/ 60000 (  0%)]\tLoss: 0.000595\n",
      "Train Epoch:  12 [  6400/ 60000 ( 11%)]\tLoss: 0.000009\n",
      "Train Epoch:  12 [ 12800/ 60000 ( 21%)]\tLoss: 0.000199\n",
      "Train Epoch:  12 [ 19200/ 60000 ( 32%)]\tLoss: 0.000085\n",
      "Train Epoch:  12 [ 25600/ 60000 ( 43%)]\tLoss: 0.000125\n",
      "Train Epoch:  12 [ 32000/ 60000 ( 53%)]\tLoss: 0.000047\n",
      "Train Epoch:  12 [ 38400/ 60000 ( 64%)]\tLoss: 0.000823\n",
      "Train Epoch:  12 [ 44800/ 60000 ( 75%)]\tLoss: 0.000835\n",
      "Train Epoch:  12 [ 51200/ 60000 ( 85%)]\tLoss: 0.000041\n",
      "Train Epoch:  12 [ 57600/ 60000 ( 96%)]\tLoss: 0.000019\n",
      "Train Epoch:  13 [     0/ 60000 (  0%)]\tLoss: 0.000019\n",
      "Train Epoch:  13 [  6400/ 60000 ( 11%)]\tLoss: 0.000147\n",
      "Train Epoch:  13 [ 12800/ 60000 ( 21%)]\tLoss: 0.000054\n",
      "Train Epoch:  13 [ 19200/ 60000 ( 32%)]\tLoss: 0.000071\n",
      "Train Epoch:  13 [ 25600/ 60000 ( 43%)]\tLoss: 0.000343\n",
      "Train Epoch:  13 [ 32000/ 60000 ( 53%)]\tLoss: 0.000023\n",
      "Train Epoch:  13 [ 38400/ 60000 ( 64%)]\tLoss: 0.000234\n",
      "Train Epoch:  13 [ 44800/ 60000 ( 75%)]\tLoss: 0.000214\n",
      "Train Epoch:  13 [ 51200/ 60000 ( 85%)]\tLoss: 0.000016\n",
      "Train Epoch:  13 [ 57600/ 60000 ( 96%)]\tLoss: 0.000133\n",
      "Train Epoch:  14 [     0/ 60000 (  0%)]\tLoss: 0.000159\n",
      "Train Epoch:  14 [  6400/ 60000 ( 11%)]\tLoss: 0.000004\n",
      "Train Epoch:  14 [ 12800/ 60000 ( 21%)]\tLoss: 0.000014\n",
      "Train Epoch:  14 [ 19200/ 60000 ( 32%)]\tLoss: 0.000013\n",
      "Train Epoch:  14 [ 25600/ 60000 ( 43%)]\tLoss: 0.000169\n",
      "Train Epoch:  14 [ 32000/ 60000 ( 53%)]\tLoss: 0.000139\n",
      "Train Epoch:  14 [ 38400/ 60000 ( 64%)]\tLoss: 0.000091\n",
      "Train Epoch:  14 [ 44800/ 60000 ( 75%)]\tLoss: 0.000149\n",
      "Train Epoch:  14 [ 51200/ 60000 ( 85%)]\tLoss: 0.000055\n",
      "Train Epoch:  14 [ 57600/ 60000 ( 96%)]\tLoss: 0.000059\n",
      "Train Epoch:  15 [     0/ 60000 (  0%)]\tLoss: 0.000000\n",
      "Train Epoch:  15 [  6400/ 60000 ( 11%)]\tLoss: 0.000013\n",
      "Train Epoch:  15 [ 12800/ 60000 ( 21%)]\tLoss: 0.000001\n",
      "Train Epoch:  15 [ 19200/ 60000 ( 32%)]\tLoss: 0.000044\n",
      "Train Epoch:  15 [ 25600/ 60000 ( 43%)]\tLoss: 0.000016\n",
      "Train Epoch:  15 [ 32000/ 60000 ( 53%)]\tLoss: 0.000009\n",
      "Train Epoch:  15 [ 38400/ 60000 ( 64%)]\tLoss: 0.000143\n",
      "Train Epoch:  15 [ 44800/ 60000 ( 75%)]\tLoss: 0.000052\n",
      "Train Epoch:  15 [ 51200/ 60000 ( 85%)]\tLoss: 0.000031\n",
      "Train Epoch:  15 [ 57600/ 60000 ( 96%)]\tLoss: 0.000017\n",
      "Train Epoch:  16 [     0/ 60000 (  0%)]\tLoss: 0.000001\n",
      "Train Epoch:  16 [  6400/ 60000 ( 11%)]\tLoss: 0.000372\n",
      "Train Epoch:  16 [ 12800/ 60000 ( 21%)]\tLoss: 0.000091\n",
      "Train Epoch:  16 [ 19200/ 60000 ( 32%)]\tLoss: 0.000011\n",
      "Train Epoch:  16 [ 25600/ 60000 ( 43%)]\tLoss: 0.000367\n",
      "Train Epoch:  16 [ 32000/ 60000 ( 53%)]\tLoss: 0.000011\n",
      "Train Epoch:  16 [ 38400/ 60000 ( 64%)]\tLoss: 0.000290\n",
      "Train Epoch:  16 [ 44800/ 60000 ( 75%)]\tLoss: 0.000014\n",
      "Train Epoch:  16 [ 51200/ 60000 ( 85%)]\tLoss: 0.000034\n",
      "Train Epoch:  16 [ 57600/ 60000 ( 96%)]\tLoss: 0.000137\n",
      "Train Epoch:  17 [     0/ 60000 (  0%)]\tLoss: 0.000037\n",
      "Train Epoch:  17 [  6400/ 60000 ( 11%)]\tLoss: 0.000027\n",
      "Train Epoch:  17 [ 12800/ 60000 ( 21%)]\tLoss: 0.000081\n",
      "Train Epoch:  17 [ 19200/ 60000 ( 32%)]\tLoss: 0.000077\n",
      "Train Epoch:  17 [ 25600/ 60000 ( 43%)]\tLoss: 0.000171\n",
      "Train Epoch:  17 [ 32000/ 60000 ( 53%)]\tLoss: 0.000219\n",
      "Train Epoch:  17 [ 38400/ 60000 ( 64%)]\tLoss: 0.000011\n",
      "Train Epoch:  17 [ 44800/ 60000 ( 75%)]\tLoss: 0.000129\n",
      "Train Epoch:  17 [ 51200/ 60000 ( 85%)]\tLoss: 0.000015\n",
      "Train Epoch:  17 [ 57600/ 60000 ( 96%)]\tLoss: 0.000100\n",
      "Train Epoch:  18 [     0/ 60000 (  0%)]\tLoss: 0.000074\n",
      "Train Epoch:  18 [  6400/ 60000 ( 11%)]\tLoss: 0.000086\n",
      "Train Epoch:  18 [ 12800/ 60000 ( 21%)]\tLoss: 0.000237\n",
      "Train Epoch:  18 [ 19200/ 60000 ( 32%)]\tLoss: 0.000036\n",
      "Train Epoch:  18 [ 25600/ 60000 ( 43%)]\tLoss: 0.000158\n",
      "Train Epoch:  18 [ 32000/ 60000 ( 53%)]\tLoss: 0.000013\n",
      "Train Epoch:  18 [ 38400/ 60000 ( 64%)]\tLoss: 0.000082\n",
      "Train Epoch:  18 [ 44800/ 60000 ( 75%)]\tLoss: 0.000028\n",
      "Train Epoch:  18 [ 51200/ 60000 ( 85%)]\tLoss: 0.000015\n",
      "Train Epoch:  18 [ 57600/ 60000 ( 96%)]\tLoss: 0.000044\n",
      "Train Epoch:  19 [     0/ 60000 (  0%)]\tLoss: 0.000082\n",
      "Train Epoch:  19 [  6400/ 60000 ( 11%)]\tLoss: 0.000032\n",
      "Train Epoch:  19 [ 12800/ 60000 ( 21%)]\tLoss: 0.000006\n",
      "Train Epoch:  19 [ 19200/ 60000 ( 32%)]\tLoss: 0.000051\n",
      "Train Epoch:  19 [ 25600/ 60000 ( 43%)]\tLoss: 0.000005\n",
      "Train Epoch:  19 [ 32000/ 60000 ( 53%)]\tLoss: 0.000179\n",
      "Train Epoch:  19 [ 38400/ 60000 ( 64%)]\tLoss: 0.000009\n",
      "Train Epoch:  19 [ 44800/ 60000 ( 75%)]\tLoss: 0.000045\n",
      "Train Epoch:  19 [ 51200/ 60000 ( 85%)]\tLoss: 0.000050\n",
      "Train Epoch:  19 [ 57600/ 60000 ( 96%)]\tLoss: 0.000054\n",
      "Train Epoch:  20 [     0/ 60000 (  0%)]\tLoss: 0.000059\n",
      "Train Epoch:  20 [  6400/ 60000 ( 11%)]\tLoss: 0.000035\n",
      "Train Epoch:  20 [ 12800/ 60000 ( 21%)]\tLoss: 0.000016\n",
      "Train Epoch:  20 [ 19200/ 60000 ( 32%)]\tLoss: 0.000004\n",
      "Train Epoch:  20 [ 25600/ 60000 ( 43%)]\tLoss: 0.000078\n",
      "Train Epoch:  20 [ 32000/ 60000 ( 53%)]\tLoss: 0.000088\n",
      "Train Epoch:  20 [ 38400/ 60000 ( 64%)]\tLoss: 0.000153\n",
      "Train Epoch:  20 [ 44800/ 60000 ( 75%)]\tLoss: 0.000076\n",
      "Train Epoch:  20 [ 51200/ 60000 ( 85%)]\tLoss: 0.000099\n",
      "Train Epoch:  20 [ 57600/ 60000 ( 96%)]\tLoss: 0.000051\n",
      "Train Epoch:  21 [     0/ 60000 (  0%)]\tLoss: 0.000066\n",
      "Train Epoch:  21 [  6400/ 60000 ( 11%)]\tLoss: 0.000006\n",
      "Train Epoch:  21 [ 12800/ 60000 ( 21%)]\tLoss: 0.000004\n",
      "Train Epoch:  21 [ 19200/ 60000 ( 32%)]\tLoss: 0.000037\n",
      "Train Epoch:  21 [ 25600/ 60000 ( 43%)]\tLoss: 0.000010\n",
      "Train Epoch:  21 [ 32000/ 60000 ( 53%)]\tLoss: 0.000024\n",
      "Train Epoch:  21 [ 38400/ 60000 ( 64%)]\tLoss: 0.000028\n",
      "Train Epoch:  21 [ 44800/ 60000 ( 75%)]\tLoss: 0.000002\n",
      "Train Epoch:  21 [ 51200/ 60000 ( 85%)]\tLoss: 0.000287\n",
      "Train Epoch:  21 [ 57600/ 60000 ( 96%)]\tLoss: 0.000033\n",
      "Train Epoch:  22 [     0/ 60000 (  0%)]\tLoss: 0.000079\n",
      "Train Epoch:  22 [  6400/ 60000 ( 11%)]\tLoss: 0.000010\n",
      "Train Epoch:  22 [ 12800/ 60000 ( 21%)]\tLoss: 0.000003\n",
      "Train Epoch:  22 [ 19200/ 60000 ( 32%)]\tLoss: 0.000050\n",
      "Train Epoch:  22 [ 25600/ 60000 ( 43%)]\tLoss: 0.000092\n",
      "Train Epoch:  22 [ 32000/ 60000 ( 53%)]\tLoss: 0.000062\n",
      "Train Epoch:  22 [ 38400/ 60000 ( 64%)]\tLoss: 0.000028\n",
      "Train Epoch:  22 [ 44800/ 60000 ( 75%)]\tLoss: 0.000069\n",
      "Train Epoch:  22 [ 51200/ 60000 ( 85%)]\tLoss: 0.000004\n",
      "Train Epoch:  22 [ 57600/ 60000 ( 96%)]\tLoss: 0.000078\n",
      "Train Epoch:  23 [     0/ 60000 (  0%)]\tLoss: 0.000021\n",
      "Train Epoch:  23 [  6400/ 60000 ( 11%)]\tLoss: 0.000032\n",
      "Train Epoch:  23 [ 12800/ 60000 ( 21%)]\tLoss: 0.000004\n",
      "Train Epoch:  23 [ 19200/ 60000 ( 32%)]\tLoss: 0.000006\n",
      "Train Epoch:  23 [ 25600/ 60000 ( 43%)]\tLoss: 0.000025\n",
      "Train Epoch:  23 [ 32000/ 60000 ( 53%)]\tLoss: 0.000028\n",
      "Train Epoch:  23 [ 38400/ 60000 ( 64%)]\tLoss: 0.000007\n",
      "Train Epoch:  23 [ 44800/ 60000 ( 75%)]\tLoss: 0.000015\n",
      "Train Epoch:  23 [ 51200/ 60000 ( 85%)]\tLoss: 0.000054\n",
      "Train Epoch:  23 [ 57600/ 60000 ( 96%)]\tLoss: 0.000075\n",
      "Train Epoch:  24 [     0/ 60000 (  0%)]\tLoss: 0.000010\n",
      "Train Epoch:  24 [  6400/ 60000 ( 11%)]\tLoss: 0.000044\n",
      "Train Epoch:  24 [ 12800/ 60000 ( 21%)]\tLoss: 0.000005\n",
      "Train Epoch:  24 [ 19200/ 60000 ( 32%)]\tLoss: 0.000003\n",
      "Train Epoch:  24 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  24 [ 32000/ 60000 ( 53%)]\tLoss: 0.000074\n",
      "Train Epoch:  24 [ 38400/ 60000 ( 64%)]\tLoss: 0.000029\n",
      "Train Epoch:  24 [ 44800/ 60000 ( 75%)]\tLoss: 0.000015\n",
      "Train Epoch:  24 [ 51200/ 60000 ( 85%)]\tLoss: 0.000021\n",
      "Train Epoch:  24 [ 57600/ 60000 ( 96%)]\tLoss: 0.000026\n",
      "Train Epoch:  25 [     0/ 60000 (  0%)]\tLoss: 0.000012\n",
      "Train Epoch:  25 [  6400/ 60000 ( 11%)]\tLoss: 0.000013\n",
      "Train Epoch:  25 [ 12800/ 60000 ( 21%)]\tLoss: 0.000002\n",
      "Train Epoch:  25 [ 19200/ 60000 ( 32%)]\tLoss: 0.000119\n",
      "Train Epoch:  25 [ 25600/ 60000 ( 43%)]\tLoss: 0.000151\n",
      "Train Epoch:  25 [ 32000/ 60000 ( 53%)]\tLoss: 0.000024\n",
      "Train Epoch:  25 [ 38400/ 60000 ( 64%)]\tLoss: 0.000065\n",
      "Train Epoch:  25 [ 44800/ 60000 ( 75%)]\tLoss: 0.000070\n",
      "Train Epoch:  25 [ 51200/ 60000 ( 85%)]\tLoss: 0.000007\n",
      "Train Epoch:  25 [ 57600/ 60000 ( 96%)]\tLoss: 0.000001\n",
      "Train Epoch:  26 [     0/ 60000 (  0%)]\tLoss: 0.000020\n",
      "Train Epoch:  26 [  6400/ 60000 ( 11%)]\tLoss: 0.000021\n",
      "Train Epoch:  26 [ 12800/ 60000 ( 21%)]\tLoss: 0.000003\n",
      "Train Epoch:  26 [ 19200/ 60000 ( 32%)]\tLoss: 0.000040\n",
      "Train Epoch:  26 [ 25600/ 60000 ( 43%)]\tLoss: 0.000032\n",
      "Train Epoch:  26 [ 32000/ 60000 ( 53%)]\tLoss: 0.000018\n",
      "Train Epoch:  26 [ 38400/ 60000 ( 64%)]\tLoss: 0.000000\n",
      "Train Epoch:  26 [ 44800/ 60000 ( 75%)]\tLoss: 0.000006\n",
      "Train Epoch:  26 [ 51200/ 60000 ( 85%)]\tLoss: 0.000060\n",
      "Train Epoch:  26 [ 57600/ 60000 ( 96%)]\tLoss: 0.000003\n",
      "Train Epoch:  27 [     0/ 60000 (  0%)]\tLoss: 0.000133\n",
      "Train Epoch:  27 [  6400/ 60000 ( 11%)]\tLoss: 0.000002\n",
      "Train Epoch:  27 [ 12800/ 60000 ( 21%)]\tLoss: 0.000009\n",
      "Train Epoch:  27 [ 19200/ 60000 ( 32%)]\tLoss: 0.000324\n",
      "Train Epoch:  27 [ 25600/ 60000 ( 43%)]\tLoss: 0.000590\n",
      "Train Epoch:  27 [ 32000/ 60000 ( 53%)]\tLoss: 0.000042\n",
      "Train Epoch:  27 [ 38400/ 60000 ( 64%)]\tLoss: 0.000088\n",
      "Train Epoch:  27 [ 44800/ 60000 ( 75%)]\tLoss: 0.000006\n",
      "Train Epoch:  27 [ 51200/ 60000 ( 85%)]\tLoss: 0.000057\n",
      "Train Epoch:  27 [ 57600/ 60000 ( 96%)]\tLoss: 0.000005\n",
      "Train Epoch:  28 [     0/ 60000 (  0%)]\tLoss: 0.000021\n",
      "Train Epoch:  28 [  6400/ 60000 ( 11%)]\tLoss: 0.000012\n",
      "Train Epoch:  28 [ 12800/ 60000 ( 21%)]\tLoss: 0.000018\n",
      "Train Epoch:  28 [ 19200/ 60000 ( 32%)]\tLoss: 0.000025\n",
      "Train Epoch:  28 [ 25600/ 60000 ( 43%)]\tLoss: 0.000033\n",
      "Train Epoch:  28 [ 32000/ 60000 ( 53%)]\tLoss: 0.000102\n",
      "Train Epoch:  28 [ 38400/ 60000 ( 64%)]\tLoss: 0.000000\n",
      "Train Epoch:  28 [ 44800/ 60000 ( 75%)]\tLoss: 0.000015\n",
      "Train Epoch:  28 [ 51200/ 60000 ( 85%)]\tLoss: 0.000046\n",
      "Train Epoch:  28 [ 57600/ 60000 ( 96%)]\tLoss: 0.000005\n",
      "Train Epoch:  29 [     0/ 60000 (  0%)]\tLoss: 0.000037\n",
      "Train Epoch:  29 [  6400/ 60000 ( 11%)]\tLoss: 0.000054\n",
      "Train Epoch:  29 [ 12800/ 60000 ( 21%)]\tLoss: 0.000019\n",
      "Train Epoch:  29 [ 19200/ 60000 ( 32%)]\tLoss: 0.000009\n",
      "Train Epoch:  29 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  29 [ 32000/ 60000 ( 53%)]\tLoss: 0.000003\n",
      "Train Epoch:  29 [ 38400/ 60000 ( 64%)]\tLoss: 0.000012\n",
      "Train Epoch:  29 [ 44800/ 60000 ( 75%)]\tLoss: 0.000002\n",
      "Train Epoch:  29 [ 51200/ 60000 ( 85%)]\tLoss: 0.000016\n",
      "Train Epoch:  29 [ 57600/ 60000 ( 96%)]\tLoss: 0.000002\n",
      "Train Epoch:  30 [     0/ 60000 (  0%)]\tLoss: 0.000077\n",
      "Train Epoch:  30 [  6400/ 60000 ( 11%)]\tLoss: 0.000136\n",
      "Train Epoch:  30 [ 12800/ 60000 ( 21%)]\tLoss: 0.000006\n",
      "Train Epoch:  30 [ 19200/ 60000 ( 32%)]\tLoss: 0.000012\n",
      "Train Epoch:  30 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  30 [ 32000/ 60000 ( 53%)]\tLoss: 0.000029\n",
      "Train Epoch:  30 [ 38400/ 60000 ( 64%)]\tLoss: 0.000001\n",
      "Train Epoch:  30 [ 44800/ 60000 ( 75%)]\tLoss: 0.000021\n",
      "Train Epoch:  30 [ 51200/ 60000 ( 85%)]\tLoss: 0.000144\n",
      "Train Epoch:  30 [ 57600/ 60000 ( 96%)]\tLoss: 0.000013\n",
      "Train Epoch:  31 [     0/ 60000 (  0%)]\tLoss: 0.000017\n",
      "Train Epoch:  31 [  6400/ 60000 ( 11%)]\tLoss: 0.000013\n",
      "Train Epoch:  31 [ 12800/ 60000 ( 21%)]\tLoss: 0.000001\n",
      "Train Epoch:  31 [ 19200/ 60000 ( 32%)]\tLoss: 0.000003\n",
      "Train Epoch:  31 [ 25600/ 60000 ( 43%)]\tLoss: 0.000016\n",
      "Train Epoch:  31 [ 32000/ 60000 ( 53%)]\tLoss: 0.000003\n",
      "Train Epoch:  31 [ 38400/ 60000 ( 64%)]\tLoss: 0.000031\n",
      "Train Epoch:  31 [ 44800/ 60000 ( 75%)]\tLoss: 0.000007\n",
      "Train Epoch:  31 [ 51200/ 60000 ( 85%)]\tLoss: 0.000007\n",
      "Train Epoch:  31 [ 57600/ 60000 ( 96%)]\tLoss: 0.000004\n",
      "Train Epoch:  32 [     0/ 60000 (  0%)]\tLoss: 0.000025\n",
      "Train Epoch:  32 [  6400/ 60000 ( 11%)]\tLoss: 0.000014\n",
      "Train Epoch:  32 [ 12800/ 60000 ( 21%)]\tLoss: 0.000022\n",
      "Train Epoch:  32 [ 19200/ 60000 ( 32%)]\tLoss: 0.000047\n",
      "Train Epoch:  32 [ 25600/ 60000 ( 43%)]\tLoss: 0.000038\n",
      "Train Epoch:  32 [ 32000/ 60000 ( 53%)]\tLoss: 0.000100\n",
      "Train Epoch:  32 [ 38400/ 60000 ( 64%)]\tLoss: 0.000017\n",
      "Train Epoch:  32 [ 44800/ 60000 ( 75%)]\tLoss: 0.000026\n",
      "Train Epoch:  32 [ 51200/ 60000 ( 85%)]\tLoss: 0.000002\n",
      "Train Epoch:  32 [ 57600/ 60000 ( 96%)]\tLoss: 0.000042\n",
      "Train Epoch:  33 [     0/ 60000 (  0%)]\tLoss: 0.000027\n",
      "Train Epoch:  33 [  6400/ 60000 ( 11%)]\tLoss: 0.000105\n",
      "Train Epoch:  33 [ 12800/ 60000 ( 21%)]\tLoss: 0.000008\n",
      "Train Epoch:  33 [ 19200/ 60000 ( 32%)]\tLoss: 0.000003\n",
      "Train Epoch:  33 [ 25600/ 60000 ( 43%)]\tLoss: 0.000005\n",
      "Train Epoch:  33 [ 32000/ 60000 ( 53%)]\tLoss: 0.000014\n",
      "Train Epoch:  33 [ 38400/ 60000 ( 64%)]\tLoss: 0.000008\n",
      "Train Epoch:  33 [ 44800/ 60000 ( 75%)]\tLoss: 0.000003\n",
      "Train Epoch:  33 [ 51200/ 60000 ( 85%)]\tLoss: 0.000004\n",
      "Train Epoch:  33 [ 57600/ 60000 ( 96%)]\tLoss: 0.000000\n",
      "Train Epoch:  34 [     0/ 60000 (  0%)]\tLoss: 0.000006\n",
      "Train Epoch:  34 [  6400/ 60000 ( 11%)]\tLoss: 0.000004\n",
      "Train Epoch:  34 [ 12800/ 60000 ( 21%)]\tLoss: 0.000008\n",
      "Train Epoch:  34 [ 19200/ 60000 ( 32%)]\tLoss: 0.000033\n",
      "Train Epoch:  34 [ 25600/ 60000 ( 43%)]\tLoss: 0.000007\n",
      "Train Epoch:  34 [ 32000/ 60000 ( 53%)]\tLoss: 0.000000\n",
      "Train Epoch:  34 [ 38400/ 60000 ( 64%)]\tLoss: 0.000003\n",
      "Train Epoch:  34 [ 44800/ 60000 ( 75%)]\tLoss: 0.000006\n",
      "Train Epoch:  34 [ 51200/ 60000 ( 85%)]\tLoss: 0.000001\n",
      "Train Epoch:  34 [ 57600/ 60000 ( 96%)]\tLoss: 0.000038\n",
      "Train Epoch:  35 [     0/ 60000 (  0%)]\tLoss: 0.000033\n",
      "Train Epoch:  35 [  6400/ 60000 ( 11%)]\tLoss: 0.000035\n",
      "Train Epoch:  35 [ 12800/ 60000 ( 21%)]\tLoss: 0.000060\n",
      "Train Epoch:  35 [ 19200/ 60000 ( 32%)]\tLoss: 0.000003\n",
      "Train Epoch:  35 [ 25600/ 60000 ( 43%)]\tLoss: 0.000004\n",
      "Train Epoch:  35 [ 32000/ 60000 ( 53%)]\tLoss: 0.000016\n",
      "Train Epoch:  35 [ 38400/ 60000 ( 64%)]\tLoss: 0.000015\n",
      "Train Epoch:  35 [ 44800/ 60000 ( 75%)]\tLoss: 0.000006\n",
      "Train Epoch:  35 [ 51200/ 60000 ( 85%)]\tLoss: 0.000002\n",
      "Train Epoch:  35 [ 57600/ 60000 ( 96%)]\tLoss: 0.000162\n",
      "Train Epoch:  36 [     0/ 60000 (  0%)]\tLoss: 0.000007\n",
      "Train Epoch:  36 [  6400/ 60000 ( 11%)]\tLoss: 0.000004\n",
      "Train Epoch:  36 [ 12800/ 60000 ( 21%)]\tLoss: 0.000025\n",
      "Train Epoch:  36 [ 19200/ 60000 ( 32%)]\tLoss: 0.000104\n",
      "Train Epoch:  36 [ 25600/ 60000 ( 43%)]\tLoss: 0.000005\n",
      "Train Epoch:  36 [ 32000/ 60000 ( 53%)]\tLoss: 0.000019\n",
      "Train Epoch:  36 [ 38400/ 60000 ( 64%)]\tLoss: 0.000050\n",
      "Train Epoch:  36 [ 44800/ 60000 ( 75%)]\tLoss: 0.000039\n",
      "Train Epoch:  36 [ 51200/ 60000 ( 85%)]\tLoss: 0.000055\n",
      "Train Epoch:  36 [ 57600/ 60000 ( 96%)]\tLoss: 0.000002\n",
      "Train Epoch:  37 [     0/ 60000 (  0%)]\tLoss: 0.000000\n",
      "Train Epoch:  37 [  6400/ 60000 ( 11%)]\tLoss: 0.000027\n",
      "Train Epoch:  37 [ 12800/ 60000 ( 21%)]\tLoss: 0.000016\n",
      "Train Epoch:  37 [ 19200/ 60000 ( 32%)]\tLoss: 0.000003\n",
      "Train Epoch:  37 [ 25600/ 60000 ( 43%)]\tLoss: 0.000003\n",
      "Train Epoch:  37 [ 32000/ 60000 ( 53%)]\tLoss: 0.000010\n",
      "Train Epoch:  37 [ 38400/ 60000 ( 64%)]\tLoss: 0.000004\n",
      "Train Epoch:  37 [ 44800/ 60000 ( 75%)]\tLoss: 0.000031\n",
      "Train Epoch:  37 [ 51200/ 60000 ( 85%)]\tLoss: 0.000026\n",
      "Train Epoch:  37 [ 57600/ 60000 ( 96%)]\tLoss: 0.000020\n",
      "Train Epoch:  38 [     0/ 60000 (  0%)]\tLoss: 0.000003\n",
      "Train Epoch:  38 [  6400/ 60000 ( 11%)]\tLoss: 0.000047\n",
      "Train Epoch:  38 [ 12800/ 60000 ( 21%)]\tLoss: 0.000009\n",
      "Train Epoch:  38 [ 19200/ 60000 ( 32%)]\tLoss: 0.000012\n",
      "Train Epoch:  38 [ 25600/ 60000 ( 43%)]\tLoss: 0.000011\n",
      "Train Epoch:  38 [ 32000/ 60000 ( 53%)]\tLoss: 0.000017\n",
      "Train Epoch:  38 [ 38400/ 60000 ( 64%)]\tLoss: 0.000108\n",
      "Train Epoch:  38 [ 44800/ 60000 ( 75%)]\tLoss: 0.000001\n",
      "Train Epoch:  38 [ 51200/ 60000 ( 85%)]\tLoss: 0.000018\n",
      "Train Epoch:  38 [ 57600/ 60000 ( 96%)]\tLoss: 0.000067\n",
      "Train Epoch:  39 [     0/ 60000 (  0%)]\tLoss: 0.000001\n",
      "Train Epoch:  39 [  6400/ 60000 ( 11%)]\tLoss: 0.000010\n",
      "Train Epoch:  39 [ 12800/ 60000 ( 21%)]\tLoss: 0.000001\n",
      "Train Epoch:  39 [ 19200/ 60000 ( 32%)]\tLoss: 0.000036\n",
      "Train Epoch:  39 [ 25600/ 60000 ( 43%)]\tLoss: 0.000010\n",
      "Train Epoch:  39 [ 32000/ 60000 ( 53%)]\tLoss: 0.000015\n",
      "Train Epoch:  39 [ 38400/ 60000 ( 64%)]\tLoss: 0.000015\n",
      "Train Epoch:  39 [ 44800/ 60000 ( 75%)]\tLoss: 0.000015\n",
      "Train Epoch:  39 [ 51200/ 60000 ( 85%)]\tLoss: 0.000014\n",
      "Train Epoch:  39 [ 57600/ 60000 ( 96%)]\tLoss: 0.000004\n",
      "Train Epoch:  40 [     0/ 60000 (  0%)]\tLoss: 0.000048\n",
      "Train Epoch:  40 [  6400/ 60000 ( 11%)]\tLoss: 0.000015\n",
      "Train Epoch:  40 [ 12800/ 60000 ( 21%)]\tLoss: 0.000009\n",
      "Train Epoch:  40 [ 19200/ 60000 ( 32%)]\tLoss: 0.000032\n",
      "Train Epoch:  40 [ 25600/ 60000 ( 43%)]\tLoss: 0.000012\n",
      "Train Epoch:  40 [ 32000/ 60000 ( 53%)]\tLoss: 0.000003\n",
      "Train Epoch:  40 [ 38400/ 60000 ( 64%)]\tLoss: 0.000043\n",
      "Train Epoch:  40 [ 44800/ 60000 ( 75%)]\tLoss: 0.000008\n",
      "Train Epoch:  40 [ 51200/ 60000 ( 85%)]\tLoss: 0.000007\n",
      "Train Epoch:  40 [ 57600/ 60000 ( 96%)]\tLoss: 0.000025\n",
      "Train Epoch:  41 [     0/ 60000 (  0%)]\tLoss: 0.000004\n",
      "Train Epoch:  41 [  6400/ 60000 ( 11%)]\tLoss: 0.000011\n",
      "Train Epoch:  41 [ 12800/ 60000 ( 21%)]\tLoss: 0.000019\n",
      "Train Epoch:  41 [ 19200/ 60000 ( 32%)]\tLoss: 0.000037\n",
      "Train Epoch:  41 [ 25600/ 60000 ( 43%)]\tLoss: 0.000012\n",
      "Train Epoch:  41 [ 32000/ 60000 ( 53%)]\tLoss: 0.000012\n",
      "Train Epoch:  41 [ 38400/ 60000 ( 64%)]\tLoss: 0.000027\n",
      "Train Epoch:  41 [ 44800/ 60000 ( 75%)]\tLoss: 0.000043\n",
      "Train Epoch:  41 [ 51200/ 60000 ( 85%)]\tLoss: 0.000009\n",
      "Train Epoch:  41 [ 57600/ 60000 ( 96%)]\tLoss: 0.000012\n",
      "Train Epoch:  42 [     0/ 60000 (  0%)]\tLoss: 0.000001\n",
      "Train Epoch:  42 [  6400/ 60000 ( 11%)]\tLoss: 0.000014\n",
      "Train Epoch:  42 [ 12800/ 60000 ( 21%)]\tLoss: 0.000004\n",
      "Train Epoch:  42 [ 19200/ 60000 ( 32%)]\tLoss: 0.000005\n",
      "Train Epoch:  42 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  42 [ 32000/ 60000 ( 53%)]\tLoss: 0.000007\n",
      "Train Epoch:  42 [ 38400/ 60000 ( 64%)]\tLoss: 0.000002\n",
      "Train Epoch:  42 [ 44800/ 60000 ( 75%)]\tLoss: 0.000032\n",
      "Train Epoch:  42 [ 51200/ 60000 ( 85%)]\tLoss: 0.000002\n",
      "Train Epoch:  42 [ 57600/ 60000 ( 96%)]\tLoss: 0.000002\n",
      "Train Epoch:  43 [     0/ 60000 (  0%)]\tLoss: 0.000006\n",
      "Train Epoch:  43 [  6400/ 60000 ( 11%)]\tLoss: 0.000000\n",
      "Train Epoch:  43 [ 12800/ 60000 ( 21%)]\tLoss: 0.000002\n",
      "Train Epoch:  43 [ 19200/ 60000 ( 32%)]\tLoss: 0.000013\n",
      "Train Epoch:  43 [ 25600/ 60000 ( 43%)]\tLoss: 0.000006\n",
      "Train Epoch:  43 [ 32000/ 60000 ( 53%)]\tLoss: 0.000000\n",
      "Train Epoch:  43 [ 38400/ 60000 ( 64%)]\tLoss: 0.000028\n",
      "Train Epoch:  43 [ 44800/ 60000 ( 75%)]\tLoss: 0.000009\n",
      "Train Epoch:  43 [ 51200/ 60000 ( 85%)]\tLoss: 0.000017\n",
      "Train Epoch:  43 [ 57600/ 60000 ( 96%)]\tLoss: 0.000008\n",
      "Train Epoch:  44 [     0/ 60000 (  0%)]\tLoss: 0.000000\n",
      "Train Epoch:  44 [  6400/ 60000 ( 11%)]\tLoss: 0.000001\n",
      "Train Epoch:  44 [ 12800/ 60000 ( 21%)]\tLoss: 0.000017\n",
      "Train Epoch:  44 [ 19200/ 60000 ( 32%)]\tLoss: 0.000171\n",
      "Train Epoch:  44 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  44 [ 32000/ 60000 ( 53%)]\tLoss: 0.000006\n",
      "Train Epoch:  44 [ 38400/ 60000 ( 64%)]\tLoss: 0.000007\n",
      "Train Epoch:  44 [ 44800/ 60000 ( 75%)]\tLoss: 0.000152\n",
      "Train Epoch:  44 [ 51200/ 60000 ( 85%)]\tLoss: 0.000149\n",
      "Train Epoch:  44 [ 57600/ 60000 ( 96%)]\tLoss: 0.000022\n",
      "Train Epoch:  45 [     0/ 60000 (  0%)]\tLoss: 0.000012\n",
      "Train Epoch:  45 [  6400/ 60000 ( 11%)]\tLoss: 0.000027\n",
      "Train Epoch:  45 [ 12800/ 60000 ( 21%)]\tLoss: 0.000062\n",
      "Train Epoch:  45 [ 19200/ 60000 ( 32%)]\tLoss: 0.000011\n",
      "Train Epoch:  45 [ 25600/ 60000 ( 43%)]\tLoss: 0.000015\n",
      "Train Epoch:  45 [ 32000/ 60000 ( 53%)]\tLoss: 0.000008\n",
      "Train Epoch:  45 [ 38400/ 60000 ( 64%)]\tLoss: 0.000020\n",
      "Train Epoch:  45 [ 44800/ 60000 ( 75%)]\tLoss: 0.000010\n",
      "Train Epoch:  45 [ 51200/ 60000 ( 85%)]\tLoss: 0.000024\n",
      "Train Epoch:  45 [ 57600/ 60000 ( 96%)]\tLoss: 0.000019\n",
      "Train Epoch:  46 [     0/ 60000 (  0%)]\tLoss: 0.000000\n",
      "Train Epoch:  46 [  6400/ 60000 ( 11%)]\tLoss: 0.000005\n",
      "Train Epoch:  46 [ 12800/ 60000 ( 21%)]\tLoss: 0.000163\n",
      "Train Epoch:  46 [ 19200/ 60000 ( 32%)]\tLoss: 0.000070\n",
      "Train Epoch:  46 [ 25600/ 60000 ( 43%)]\tLoss: 0.000016\n",
      "Train Epoch:  46 [ 32000/ 60000 ( 53%)]\tLoss: 0.000011\n",
      "Train Epoch:  46 [ 38400/ 60000 ( 64%)]\tLoss: 0.000017\n",
      "Train Epoch:  46 [ 44800/ 60000 ( 75%)]\tLoss: 0.000012\n",
      "Train Epoch:  46 [ 51200/ 60000 ( 85%)]\tLoss: 0.000048\n",
      "Train Epoch:  46 [ 57600/ 60000 ( 96%)]\tLoss: 0.000004\n",
      "Train Epoch:  47 [     0/ 60000 (  0%)]\tLoss: 0.000047\n",
      "Train Epoch:  47 [  6400/ 60000 ( 11%)]\tLoss: 0.000005\n",
      "Train Epoch:  47 [ 12800/ 60000 ( 21%)]\tLoss: 0.000049\n",
      "Train Epoch:  47 [ 19200/ 60000 ( 32%)]\tLoss: 0.000012\n",
      "Train Epoch:  47 [ 25600/ 60000 ( 43%)]\tLoss: 0.000025\n",
      "Train Epoch:  47 [ 32000/ 60000 ( 53%)]\tLoss: 0.000001\n",
      "Train Epoch:  47 [ 38400/ 60000 ( 64%)]\tLoss: 0.000004\n",
      "Train Epoch:  47 [ 44800/ 60000 ( 75%)]\tLoss: 0.000005\n",
      "Train Epoch:  47 [ 51200/ 60000 ( 85%)]\tLoss: 0.000001\n",
      "Train Epoch:  47 [ 57600/ 60000 ( 96%)]\tLoss: 0.000044\n",
      "Train Epoch:  48 [     0/ 60000 (  0%)]\tLoss: 0.000051\n",
      "Train Epoch:  48 [  6400/ 60000 ( 11%)]\tLoss: 0.000005\n",
      "Train Epoch:  48 [ 12800/ 60000 ( 21%)]\tLoss: 0.000031\n",
      "Train Epoch:  48 [ 19200/ 60000 ( 32%)]\tLoss: 0.000030\n",
      "Train Epoch:  48 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  48 [ 32000/ 60000 ( 53%)]\tLoss: 0.000013\n",
      "Train Epoch:  48 [ 38400/ 60000 ( 64%)]\tLoss: 0.000006\n",
      "Train Epoch:  48 [ 44800/ 60000 ( 75%)]\tLoss: 0.000003\n",
      "Train Epoch:  48 [ 51200/ 60000 ( 85%)]\tLoss: 0.000006\n",
      "Train Epoch:  48 [ 57600/ 60000 ( 96%)]\tLoss: 0.000007\n",
      "Train Epoch:  49 [     0/ 60000 (  0%)]\tLoss: 0.000000\n",
      "Train Epoch:  49 [  6400/ 60000 ( 11%)]\tLoss: 0.000004\n",
      "Train Epoch:  49 [ 12800/ 60000 ( 21%)]\tLoss: 0.000001\n",
      "Train Epoch:  49 [ 19200/ 60000 ( 32%)]\tLoss: 0.000000\n",
      "Train Epoch:  49 [ 25600/ 60000 ( 43%)]\tLoss: 0.000001\n",
      "Train Epoch:  49 [ 32000/ 60000 ( 53%)]\tLoss: 0.000003\n",
      "Train Epoch:  49 [ 38400/ 60000 ( 64%)]\tLoss: 0.000037\n",
      "Train Epoch:  49 [ 44800/ 60000 ( 75%)]\tLoss: 0.000010\n",
      "Train Epoch:  49 [ 51200/ 60000 ( 85%)]\tLoss: 0.000012\n",
      "Train Epoch:  49 [ 57600/ 60000 ( 96%)]\tLoss: 0.000010\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import ComplexBatchNorm2d, ComplexConv2d, ComplexLinear\n",
    "from complexPyTorch.complexFunctions import complex_relu, complex_max_pool2d\n",
    "\n",
    "batch_size = 64\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../data', train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST('../data', train=False, transform=trans, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 5, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 5, 1)\n",
    "        self.fc1 = ComplexLinear(4*4*20, 500)\n",
    "        self.fc2 = ComplexLinear(500, 10)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,4*4*20)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device).type(torch.complex64), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item())\n",
    "            )\n",
    "\n",
    "# Run training on 50 epochs\n",
    "for epoch in range(50):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "155\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "sum  = 0\n",
    "for i in range(11):\n",
    "    sum+=i\n",
    "print(sum)\n",
    "\n",
    "sum  = 0\n",
    "for i in range(11, 21):\n",
    "    sum+=i\n",
    "print(sum)\n",
    "\n",
    "sum = 0\n",
    "for i in range(21, 31):\n",
    "    sum+=i\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
